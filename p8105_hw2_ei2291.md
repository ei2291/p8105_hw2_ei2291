p8105_hw2_ei2291
================
Eman Ibrahim
2025-09-28

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.4     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

\##Problem 1

Import and cleaning the datasets

``` r
pols_month_df=
  read_csv("fivethirtyeight_datasets/pols-month.csv") |> 
  janitor::clean_names()
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
unemployment_df=
  read_csv("fivethirtyeight_datasets/unemployment.csv") |> 
  janitor::clean_names()
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
snp_df=
  read_csv("fivethirtyeight_datasets/snp.csv") |> 
  janitor::clean_names()
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Clean pols-month.csv

``` r
pols_month_df=
  separate(pols_month_df, mon, into = c("year", "month", "day"), sep = "-") |> 
  mutate(
    month=month.name[as.numeric(month)],
    prezident=ifelse(prez_gop ==1, "gop", "dem"),
    year=as.integer(year)
    ) |> 
    select(-prez_gop, -prez_dem, -day)
```

Clean snp.csv

``` r
snp_df=
  separate(snp_df,date, into=c("month", "day", "year"), sep = "/") |> 
  mutate(
    year=ifelse(
      as.integer(year)>=50, 
      as.integer(year)+1900, 
      as.integer(year)+2000),
    month=month.name[as.numeric(month)]
  ) |> 
  arrange(year, month) |> 
  select(year, month, everything(),-day) 
```

Clean unemployment.csv

``` r
unemployment_df=
  pivot_longer(unemployment_df,
    cols= jan:dec,
    names_to= "month",
    values_to="unemployment"
  ) |> 
  mutate(
    month=str_to_title(month),
    month=match(month, month.abb),
    month=month.name[month]
  ) |> 
  arrange(year, month) 
```

Merging snp into pols

``` r
merge_df=
  left_join(pols_month_df, snp_df, by= c("year", "month")) |> 
  left_join(unemployment_df, by = c("year","month")) |> 
  arrange(year, month)
```

About the datasets

From my understanding the `pols-momths.csv` contains data on pols for
each U.S. party, the `snp.csv` contains data on stock market I think,
and the `unemployment.csv` is on unemployment rates in the U.S. All
datasets show what happened each month throughout those years. We then
cleaned and merged all by year and month. The key variables are: `year`,
`month`, `prezident`,`close`, and `unemployment`.

\##Problem 2

``` r
library(tidyverse)
library(readxl)
```

Clean Mr. Trash Wheel dataset

``` r
Mr_trash_df=
  read_excel("trash_wheel_collection_data.xlsx",
             sheet="Mr. Trash Wheel",
             skip=1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(sports_balls=as.integer(round(sports_balls)),
         year=as.integer(year)
         ) |> 
  select(-x15,-x16)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

Clean Professor Trash Wheel dataset

``` r
Professor_trash_df=
  read_excel("trash_wheel_collection_data.xlsx", sheet= "Professor Trash Wheel", skip=1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(wheel="Professor Trash Wheel",
         year=as.integer(year))
```

Clean Gwynnda Trash Wheel dataset

``` r
Gwynnda_trash_df=
  read_excel("trash_wheel_collection_data.xlsx", sheet= "Gwynnda Trash Wheel", skip=1) |> 
  janitor::clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(wheel="Gwynnda",
         year=as.integer(year))
```

Combining all datasets

``` r
trash_df=
  bind_rows(Mr_trash_df, 
            Professor_trash_df, 
            Gwynnda_trash_df) |> 
  relocate(wheel, year, month) |> 
  arrange(wheel, year, month)
```

Check for observation in `trash_df` and key variables

``` r
dim(trash_df)
```

    ## [1] 1033   15

``` r
names(trash_df)
```

    ##  [1] "wheel"              "year"               "month"             
    ##  [4] "dumpster"           "date"               "weight_tons"       
    ##  [7] "volume_cubic_yards" "plastic_bottles"    "polystyrene"       
    ## [10] "cigarette_butts"    "glass_bottles"      "plastic_bags"      
    ## [13] "wrappers"           "sports_balls"       "homes_powered"

There are 1033 observations and 15 variables. Key variables are `wheel`,
`dumpster`, `month`, `year`, `weight_tons`, `cigarette_butts`, and
`sports_balls`. There are other variables that I didn’t mention that can
be helpful for the analyses.

Total weight of trash collected by Prof. Trash

``` r
total_weight_Professor_trash_df=
  filter(trash_df, wheel=="Professor Trash Wheel") |> 
  summarize(total_weight= sum(weight_tons, na.rm=TRUE))
```

The total weight of trash collected by Professor Trash Wheel is 246.74
tons.

Total no. of cigarette butts collected by Gwynnda (June 2022)

``` r
total_cigarette_butts_Gwynnda_trash_df=
  filter(trash_df, 
         wheel=="Gwynnda",    month=="June", year==2022) |>
  summarize(total_cigarette_butts = sum (cigarette_butts, na.rm=TRUE))
```

The total number of cigarette butts collected by Gwynnda in June 2022
was 18120 butts.

\##Problem 3

``` r
library(tidyverse)
```

Import and clean dataset

``` r
zipcodes_county_df=
  read_csv("Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(
    county = case_when(
    county == "New York" ~ "Manhattan",
    county == "Kings" ~ "Brooklyn",
    county == "Richmond" ~ "Staten Island",
    TRUE ~ county)
  ) |> 
  distinct(zip_code,.keep_all=TRUE)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Import and clean dataset2

``` r
zipcodes_neighborhood_df=
  read_csv("Zip codes neighborhood.csv") |> 
  janitor::clean_names() |> 
  pivot_longer(
    cols = starts_with ("x20"),
    names_to= "date",
    values_to = "zori"
  ) |> 
  rename(county=county_name,
         zip_code=region_id) |> 
  mutate(date = lubridate::ymd(str_remove(date, "x")),
         county = case_when(
    county == "New York County" ~ "Manhattan",
    county == "Kings County" ~ "Brooklyn",
    county == "Richmond County" ~ "Staten Island",
    county == "Queens County" ~ "Queens",
    county == "Bronx County" ~ "Bronx",
    TRUE ~ county))
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Join datasets

``` r
combined_df=
  left_join(zipcodes_neighborhood_df, zipcodes_county_df, by="zip_code") |> 
  select(-county.y) |> 
  rename(county = county.x) |> 
  relocate(zip_code,county) |> 
  arrange(zip_code, county)
```

No. of observations, unique zip codes, and unique neighborhoods

``` r
nrow(combined_df)
```

    ## [1] 17284

``` r
n_distinct(combined_df$zip_code)
```

    ## [1] 149

``` r
n_distinct(combined_df$region_name)
```

    ## [1] 149

There are 17,284 total number of observations; 149 number of unique
zipcodes, and 149 number of unique neighborhoods.

``` r
missing_zip_df =
  anti_join(zipcodes_county_df, combined_df, by= "zip_code")

missing_zip_df |> 
  count(county_code, sort=TRUE)
```

    ## # A tibble: 5 × 2
    ##   county_code     n
    ##   <chr>       <int>
    ## 1 061           147
    ## 2 081            81
    ## 3 047            48
    ## 4 005            30
    ## 5 085            14

``` r
missing_zip_df |> 
  count(county,sort=TRUE )
```

    ## # A tibble: 5 × 2
    ##   county            n
    ##   <chr>         <int>
    ## 1 Manhattan       147
    ## 2 Queens           81
    ## 3 Brooklyn         48
    ## 4 Bronx            30
    ## 5 Staten Island    14

When comparing the dataset, county codes with the most missing zip codes
in zillow are county 061, 081, 047, 005, and 085; which are Manhattan,
Queens, Brooklyn, Bronx, and Staten Island, respectively. Some reasons
why they’re missing/excluded in zillow could be because the zipcodes may
be recently reassigned or new and not yet on zillow, or maybe the
zipcodes might be more industrial area and little to no residential
housing.

``` r
covid_df=
  combined_df |> 
  filter(lubridate::year(date) %in% c(2020, 2021) &
         lubridate::month(date) ==1) |> 
  select(zip_code, county,region_name, date, zori) |> 
  pivot_wider(
    names_from =date,
    values_from=zori
  ) |> 
  mutate(drop=`2020-01-31` - `2021-01-31`) |> 
  arrange (drop) |> 
  slice_min(drop, n=10)
```

The table provides the 10 zipcodes that had the largest drop in rental
prices from January of 2020 to January of 2021. Queens, Bronx, and
Brooklyn had the biggest decrease.
